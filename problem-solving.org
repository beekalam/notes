#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/main.css" />
* How much time is too much (to put into a single problem)?
I would consider having more than one problem 'on the go' at a
time. Similar to the concept often repeated at school before exams,
"if you get stuck on a problem, move on and come back to it
later". There are two clear benefits I can see to this approach:

 - *You find the answer to the problem you're stuck on by solving a new problem.*
 - Over the passage of time, the answer to your problem finds its way into your brain through the ether.

http://math.stackexchange.com/questions/232632/how-much-time-is-too-much-to-put-into-a-single-problem
http://math.stackexchange.com/questions/689214/some-questions-regarding-preparing-for-math-olympiads-searched-but-didnt-get-a

 1) Read the problem completely twice.
 2) Solve the problem manually with 3 sets of sample data.
 3) Optimize the manual steps.
 4) Write the manual steps as comments or pseudo-code.
 5) Replace the comments or pseudo-code with real code.
 6) Optimize the real code.

https://simpleprogrammer.com/2011/01/08/solving-problems-breaking-it-down/
* technique

| technique                        | description                                                                     |
|----------------------------------+---------------------------------------------------------------------------------+
| Divide-and-conquer               | Can you divide the problem into two or more smaller independent subproblems and |
|                                  | solve the original problem using solutions to the subproblems?                  |
| Recursion , dynamic programmming | If you have access to solutions for smaller in- stances of a given problem,     |
|                                  | , can you easily con- struct a solution to the problem?                         |

* general strategies
** Exhaustive Search
Theoretically, many puzzles can be solved by exhaustive search—a
problem-solving strategy that simply tries all possible candidate
solutions until a solution to the problem is found.  

The most important limitation of exhaustive search is its
inefficiency.as a rule, the number of solution candidates that need to
be processed grows at least exponentially with the problem size,
making the approach inappropriate not only for a human but often for a
computer as well.

*** cons
****  Mechanics of generating all possible solution candidate
For some problems, such candidates compose a well-structured set. For
example, candidate arrangements of the first nine positive integers in
the cells of the 3 × 3 table (see the Magic Square example above) can
be obtained as permutations of these numbers, for which several
algorithms are known. There are many problems, however, where solution
candidates do not form a set with such a regular structure.

**** The more fundamental, difficulty lies in the number of solution candidates that need to be generated and processed

Typically, the size of this set grows at least exponentially with the
problem size. Therefore, exhaustive search is practical only for very
small instances of such problems.

** Backtracking
Backtracking is an important improvement over the brute-force approach
of exhaustive search. *It provides a convenient method for generating*
*candidate solutions while making it possible to avoid generating*
*unnecessary candidates.* The main idea is to construct solutions one
component at a time and evaluate such partially constructed candidates
as follows: If a partially constructed solution can be developed
further without violating the problem’s constraints, it is done by
taking the first remaining legitimate option for the next
component. If there is no legitimate option for the next component, no
alternatives for any remaining component need to be considered. In
this case, the algorithm backtracks to replace the last component of
the partially constructed solution with the next option for that
component.


Typically, backtracking involves undoing a number of wrong choices—the
smaller this number, the faster the algorithm finds a
solution. Although in the worst-case scenario a backtracking algorithm
may end up generating all the same candidate solutions as an
exhaustive search, this rarely happens.

It is convenient to interpret a backtracking algorithm as a process of
constructing a tree that mirrors decisions being made. Computer
scientists use the term tree to describe hierarchical structures such
as family trees and organizational charts. A tree is usually shown
with its root (the only node without a parent) on the top and its
leaves (nodes without children) on or closer to the bottom of the
diagram. This is nothing but a convenient typographical convention,
however. For a backtracking algorithm, such a tree is called a
state-space tree. The root of a state-space tree corresponds to the
start of a solution construction process; we consider the root to be
on the zero level of the tree. The root’s children—on the first level
of the tree—correspond to possible choices of the first component of a
solution (e.g., the cell to contain 1 in the magic square
construction). Their children—the nodes on the second level—correspond
to possible choices of the second component of a solution, and so
on. Leaves can be of two kinds. The first kind—called nonpromising
nodes or dead ends—correspond to partially constructed candidates that
cannot lead to a solution. After establishing that a particular node
is nonpromising, a backtracking algorithm terminates the node (the
tree is said to be pruned), undoes the decision regarding the last
component of the candidate solution by backtracking to the parent of
the nonpromising node, and considers another choice for that
component. The second kind of a leaf provides a solution to the
problem. If a single solution suffices, the algorithm stops; if other
solutions need to be searched for, the algorithm continues searching
for them by backtracking to the leaf’s parent.


 
* good reads
https://www.amazon.com/Best-Sellers-Books-Decision-Making-Problem-Solving/zgbs/books/2679

